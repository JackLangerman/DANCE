{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ioutils as io\n",
    "import skimage\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import natsort\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sys.path = ['./cyclegan/'] + sys.path\n",
    "\n",
    "from my_networks import scr_net, CreateDiscriminator\n",
    "from models.base_model import BaseModel\n",
    "from models import networks\n",
    "\n",
    "from scr_utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 or L2 norm for the regression loss\n",
    "norm = 2\n",
    "# training batch size\n",
    "b_size = 48\n",
    "# total training update steps\n",
    "num_steps = 20000\n",
    "# λL2 = 1, λGAN_F = 0.7 and λGAN_Y = 0.4 * 0.7 = 0.28.\n",
    "# loss_trg = lambda_adv_target * loss_D_trg_fake + loss_seg_trg + 0.4 * lambda_adv_target * loss_D_2_trg_fake\n",
    "lambda_adv_target = 0.7\n",
    "# print loss every print_interval steps\n",
    "print_interval = 500\n",
    "# validate current model performance every test_interval step\n",
    "test_interval = 1000\n",
    "\n",
    "date = '0118'\n",
    "version = 0\n",
    "NAME = 'scr_cyclegan_b{}_{}_his_cyclegan_adv_2gan_version{}'.format(b_size, date, version)\n",
    "\n",
    "data_path = '/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000 (100000, 4, 4)\n",
      "1637 1637 (1637, 4, 4)\n",
      "28411 28411 (28411, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "render_img_paths, render_scr_paths, render_poses = make_render_dataset(data_path)\n",
    "### set the render_img_paths to histogram matched\n",
    "render_img_paths = natsort.natsorted(glob.glob('/scratch/zq415/grammar_cor/pose/pose_estimate/train_render_matched'+'/**/*.png', recursive=True))\n",
    "print(len(render_img_paths), len(render_scr_paths), render_poses.shape)\n",
    "\n",
    "\n",
    "real_val_img_paths, val_scr_label_paths, val_poses = make_render_dataset(data_path, train_flag=False)\n",
    "\n",
    "\n",
    "print(len(real_val_img_paths), len(val_scr_label_paths), val_poses.shape)\n",
    "\n",
    "\n",
    "real_train_img_paths = natsort.natsorted(glob.glob('/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data/train_real_imgs'+'/**/*.png', recursive=True))\n",
    "train_scr_label_paths = natsort.natsorted(glob.glob('/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data/train_real_scene_coords'+'/**/*.tiff', recursive=True))\n",
    "real_train_rvecs = io.load(os.path.join(data_path, 'train_real_poses/2/rvecs.json'))\n",
    "real_train_rvecs += io.load(os.path.join(data_path, 'train_real_poses/5/rvecs.json'))\n",
    "real_train_tvecs = io.load(os.path.join(data_path, 'train_real_poses/2/tvecs.json'))\n",
    "real_train_tvecs += io.load(os.path.join(data_path, 'train_real_poses/5/tvecs.json'))\n",
    "train_poses = []\n",
    "for i in range(len(real_train_rvecs)):\n",
    "    cur_pose = np.eye(4)\n",
    "    cur_pose[:3, :3] = cv2.Rodrigues(np.squeeze(np.array(real_train_rvecs[i])))[0]\n",
    "    cur_pose[:3, 3] = np.array(real_train_tvecs[i]).T\n",
    "    train_poses.append(cur_pose[np.newaxis,:,:])\n",
    "train_poses = np.concatenate(train_poses)\n",
    "\n",
    "print(len(real_train_img_paths), len(real_train_rvecs), train_poses.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val_dataset = dataset_scr(real_val_img_paths, val_poses, val_scr_label_paths,\n",
    "                              transform=transforms.Compose([fix_crop()]))\n",
    "real_val_dataloader = DataLoader(real_val_dataset, batch_size=100,\n",
    "                            shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "render_train_dataset = dataset_scr(render_img_paths, render_poses, render_scr_paths,\n",
    "                               transform=transforms.Compose([random_crop()]), max_iters=num_steps*b_size)\n",
    "render_train_dataloader = DataLoader(render_train_dataset, batch_size=b_size,\n",
    "                            shuffle=True, num_workers=4)\n",
    "\n",
    "real_train_dataset = dataset_scr(real_train_img_paths, train_poses, train_scr_label_paths,\n",
    "                               transform=transforms.Compose([random_crop()]), max_iters=num_steps*b_size)\n",
    "real_train_dataloader = DataLoader(real_train_dataset, batch_size=b_size,\n",
    "                            shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    \"\"\"This class implements an image buffer that stores previously generated images.\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_size=200):\n",
    "        self.pool_size = pool_size\n",
    "        self.num_imgs = 0\n",
    "        self.images = []\n",
    "    def query(self, images): # images b,c,h,w torch tensor.\n",
    "        \"\"\"Return an image from the pool.\n",
    "        Parameters:\n",
    "            images: the latest generated images from the generator\n",
    "        Returns images from the buffer.\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)   # collect all the images and return\n",
    "        return return_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, render_train_loader, optimizer, criterion, record, model_D, optimizer_D, model_D_2, optimizer_D_2,\n",
    "         real_train_dataloader):\n",
    "    model.train()\n",
    "    model_D.train()\n",
    "    model_D_2.train()\n",
    "    trg_lbl_pool = ImagePool(pool_size=200)\n",
    "    src_lbl_pool = ImagePool(pool_size=200)\n",
    "    targetloader_iter, sourceloader_iter = iter(real_train_dataloader), iter(render_train_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "        model_D_2.zero_grad()\n",
    "        \n",
    "        for param in model_D.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model_D_2.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        source_sample_batch = sourceloader_iter.next()\n",
    "        src_img, src_lbl = source_sample_batch['image'], source_sample_batch['scr']\n",
    "        src_img, src_lbl = src_img.to(device, dtype=torch.float), src_lbl.to(device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            src_img = netG((src_img-0.5)/0.5)*0.5+0.5\n",
    "            \n",
    "        src_feat, src_pre = model(src_img)\n",
    "        loss_reg_src = criterion(src_pre, torch.nn.functional.interpolate(src_lbl, scale_factor=1/8.0, mode='bilinear'),p=norm)\n",
    "        loss_reg_src.backward()\n",
    "    \n",
    "        target_sample_batch = targetloader_iter.next()\n",
    "        trg_img, trg_lbl = target_sample_batch['image'], target_sample_batch['scr']\n",
    "        trg_img, trg_lbl = trg_img.to(device, dtype=torch.float), trg_lbl.to(device, dtype=torch.float)\n",
    "        trg_feat, trg_pre = model(trg_img)\n",
    "        trg_lbl = torch.nn.functional.interpolate(trg_lbl, scale_factor=1/8.0, mode='bilinear')\n",
    "                    \n",
    "        outD_trg = model_D(trg_feat, 0)\n",
    "        loss_D_trg_fake = model_D.loss\n",
    "        \n",
    "        outD_trg_2 = model_D_2(trg_pre, 0)\n",
    "        loss_D_2_trg_fake = model_D_2.loss\n",
    "        \n",
    "        loss_trg = lambda_adv_target * loss_D_trg_fake + 0.4 * lambda_adv_target * loss_D_2_trg_fake\n",
    "        loss_trg.backward()\n",
    "    \n",
    "        for param in model_D.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model_D_2.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        src_feat, trg_feat = src_feat.detach(), trg_feat.detach()\n",
    "        outD_src = model_D(src_feat, 0)\n",
    "        loss_D_src_real = model_D.loss / 2\n",
    "        loss_D_src_real.backward()\n",
    "        outD_trg = model_D(trg_feat, 1)\n",
    "        loss_D_trg_real = model_D.loss / 2\n",
    "        loss_D_trg_real.backward()\n",
    "        \n",
    "        src_pre, trg_pre = src_lbl_pool.query(torch.nn.functional.interpolate(src_lbl, scale_factor=1/8.0, mode='bilinear')), trg_lbl_pool.query(trg_pre.detach())\n",
    "        outD_src_2 = model_D_2(src_pre, 0)\n",
    "        loss_D_src_real_2 = model_D_2.loss / 2\n",
    "        loss_D_src_real_2.backward()\n",
    "        outD_trg_2 = model_D_2(trg_pre, 1)\n",
    "        loss_D_trg_real_2 = model_D_2.loss / 2\n",
    "        loss_D_trg_real_2.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "        optimizer_D.step()\n",
    "        optimizer_D_2.step()\n",
    "        \n",
    "        running_loss += loss_reg_src.item()\n",
    "        \n",
    "        if (i+1) % print_interval == 0:\n",
    "            out_str = \"iter {}, current loss {}.\\n\".format(i+1,running_loss/print_interval)\n",
    "            print(out_str)\n",
    "            record.write(out_str)\n",
    "            record.flush()\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if (i+1) % test_interval == 0:\n",
    "            real_val_scr_predicts, val_scrs, val_true_poses = validate(model, real_val_dataloader)\n",
    "            \n",
    "            out_str = 'real_mean_scr_error: {}.\\n'.format(compute_mean_error(val_scrs, real_val_scr_predicts))\n",
    "            print(out_str)\n",
    "            record.write(out_str)\n",
    "            record.flush()\n",
    "            \n",
    "            real_val_median = get_median(real_val_scr_predicts, val_true_poses)\n",
    "            out_str = 'real_val, r_median: {}, t_median: {}.\\n'.format(real_val_median[0], real_val_median[1])\n",
    "            print(out_str)\n",
    "            record.write(out_str)\n",
    "            record.flush()\n",
    "            \n",
    "            \n",
    "            torch.save(model.state_dict(), './check_point/scr_b{}_iter{}_norm{}_{}_his_cyclegan_adv2gan_ensemble{}.pth'.format(b_size,i,norm,date,version))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResnetGenerator(\n",
       "    (model): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (21): ReLU(inplace=True)\n",
       "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (27): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG_device = [i for i in range(torch.cuda.device_count())]\n",
    "netG = networks.define_G(3, 3, 64, 'resnet_9blocks', 'instance', False, 'normal', 0.02, netG_device)\n",
    "state_dict = torch.load('./cyclegan/checkpoints/match2real_cyclegan_scr_2gpu_1024_noidentity/4_net_G_A.pth', map_location=str(device))\n",
    "# state_dict = torch.load('./cyclegan/checkpoints/match2real_cyclegan_scr_2gpu_1011/4_net_G_A.pth', map_location=str(device))\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if 'module.' not in k:\n",
    "        k = 'module.'+ k\n",
    "        new_state_dict[k]=v\n",
    "netG.load_state_dict(new_state_dict)\n",
    "for param in netG.parameters():\n",
    "    param.requires_grad = False\n",
    "netG.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_D, optimizer_D = CreateDiscriminator(input_channel=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_D_2, optimizer_D_2 = CreateDiscriminator(input_channel=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11572803\n"
     ]
    }
   ],
   "source": [
    "net = scr_net()\n",
    "net.to(device)\n",
    "model_D.to(device)\n",
    "model_D_2.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "    model_D = nn.DataParallel(model_D)\n",
    "    model_D_2 = nn.DataParallel(model_D_2)\n",
    "    \n",
    "model_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(model_total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=0.00001)\n",
    "criterion = maskedPnorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 2, batch_size: 48.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = open('./save_info/'+ NAME +'.txt','w+')\n",
    "\n",
    "basic_str = \"norm: {}, batch_size: {}.\\n\".format(norm, b_size)\n",
    "print(basic_str)\n",
    "record.write(basic_str)\n",
    "record.flush()\n",
    "\n",
    "train(net, device, render_train_dataloader, optimizer, criterion, record, model_D, optimizer_D, model_D_2, optimizer_D_2,\n",
    "         real_train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
