{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import natsort\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from tqdm import trange, tqdm\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import sklearn.metrics as metrics\n",
    "from pyquaternion import Quaternion\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from my_networks import scr_net, CreateDiscriminator\n",
    "\n",
    "from skimage import data\n",
    "from skimage import exposure\n",
    "from skimage.exposure import match_histograms\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the location of training rendered images\n",
    "main_path = '/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data'\n",
    "# the location to save the rendered images after histogram matching\n",
    "root_save_path = '../train_render_matched'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_img_paths = natsort.natsorted(glob.glob(main_path+'/rendered/**/*.png', recursive=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 8 real camera images to provide the target histogram information\n",
    "ref_path1 = '/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data/train_real_imgs/2'\n",
    "ref_path2 = '/scratch/zq415/grammar_cor/pose/pose_estimate/icra_data/train_real_imgs/5'\n",
    "\n",
    "reference_1 = np.asarray(Image.open(os.path.join(ref_path1, '01590.png')).convert('RGB'))\n",
    "reference_2 = np.asarray(Image.open(os.path.join(ref_path1, '03358.png')).convert('RGB'))\n",
    "reference_3 = np.asarray(Image.open(os.path.join(ref_path1, '08140.png')).convert('RGB'))\n",
    "reference_4 = np.asarray(Image.open(os.path.join(ref_path1, '16748.png')).convert('RGB'))\n",
    "\n",
    "reference_5 = np.asarray(Image.open(os.path.join(ref_path2, '00934.png')).convert('RGB'))\n",
    "reference_6 = np.asarray(Image.open(os.path.join(ref_path2, '06168.png')).convert('RGB'))\n",
    "reference_7 = np.asarray(Image.open(os.path.join(ref_path2, '08578.png')).convert('RGB'))\n",
    "reference_8 = np.asarray(Image.open(os.path.join(ref_path2, '39896.png')).convert('RGB'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_num = 0\n",
    "for i in range(len(render_img_paths)):\n",
    "    matched_num += 1\n",
    "    print(matched_num)\n",
    "    sub_folder_name = render_img_paths[i].split('/')[-2]\n",
    "    img_name = render_img_paths[i].split('/')[-1]\n",
    "    \n",
    "    img_save_path = os.path.join(root_save_path, sub_folder_name)\n",
    "    if not os.path.exists(img_save_path):\n",
    "        os.makedirs(img_save_path)\n",
    "    img_save_name = os.path.join(img_save_path, img_name)\n",
    "    if os.path.exists(img_save_name):\n",
    "        continue\n",
    "    \n",
    "    render_img = np.asarray(Image.open(render_img_paths[i]).convert('RGB'))\n",
    "    \n",
    "    matched_1 = match_histograms(render_img, reference_1, multichannel=True)\n",
    "    matched_2 = match_histograms(render_img, reference_2, multichannel=True)\n",
    "    matched_3 = match_histograms(render_img, reference_3, multichannel=True)\n",
    "    matched_4 = match_histograms(render_img, reference_4, multichannel=True)\n",
    "    \n",
    "    matched_5 = match_histograms(render_img, reference_5, multichannel=True)\n",
    "    matched_6 = match_histograms(render_img, reference_6, multichannel=True)\n",
    "    matched_7 = match_histograms(render_img, reference_7, multichannel=True)\n",
    "    matched_8 = match_histograms(render_img, reference_8, multichannel=True)\n",
    "    \n",
    "    # take the average\n",
    "    matched = np.array(matched_1/8.0+matched_2/8.0+matched_3/8.0+matched_4/8.0+\n",
    "                       matched_5/8.0+matched_6/8.0+matched_7/8.0+matched_8/8.0, dtype=np.uint8)\n",
    "    \n",
    "    \n",
    "    Image.fromarray(matched).save(img_save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
